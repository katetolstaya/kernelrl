cfg/kq_mccar.cfg
MountainCarContinuous-v0
Training for 500000 steps ...
Interval 1 (0 steps performed)
999
1 episodes - episode_rewards: -34.214 [-34.214, -34.214] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 2 (1000 steps performed)
999
1 episodes - episode_rewards: -34.029 [-34.029, -34.029] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 3 (2000 steps performed)
999
1 episodes - episode_rewards: -33.871 [-33.871, -33.871] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 4 (3000 steps performed)
999
1 episodes - episode_rewards: -33.714 [-33.714, -33.714] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 5 (4000 steps performed)
999
1 episodes - episode_rewards: -30.548 [-30.548, -30.548] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 6 (5000 steps performed)
999
1 episodes - episode_rewards: -32.854 [-32.854, -32.854] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 7 (6000 steps performed)
999
1 episodes - episode_rewards: -32.620 [-32.620, -32.620] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 8 (7000 steps performed)
999
1 episodes - episode_rewards: -34.394 [-34.394, -34.394] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 9 (8000 steps performed)
999
1 episodes - episode_rewards: -33.148 [-33.148, -33.148] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 10 (9000 steps performed)
999
1 episodes - episode_rewards: -34.747 [-34.747, -34.747] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 11 (10000 steps performed)
999
1 episodes - episode_rewards: -31.736 [-31.736, -31.736] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 12 (11000 steps performed)
999
1 episodes - episode_rewards: -33.442 [-33.442, -33.442] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 13 (12000 steps performed)
999
1 episodes - episode_rewards: -32.159 [-32.159, -32.159] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 14 (13000 steps performed)
999
1 episodes - episode_rewards: -32.805 [-32.805, -32.805] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 15 (14000 steps performed)
999
1 episodes - episode_rewards: -31.713 [-31.713, -31.713] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 16 (15000 steps performed)
999
1 episodes - episode_rewards: -33.612 [-33.612, -33.612] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 17 (16000 steps performed)
999
1 episodes - episode_rewards: -32.688 [-32.688, -32.688] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 18 (17000 steps performed)
999
1 episodes - episode_rewards: -33.911 [-33.911, -33.911] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 19 (18000 steps performed)
999
1 episodes - episode_rewards: -34.411 [-34.411, -34.411] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 20 (19000 steps performed)
999
1 episodes - episode_rewards: -33.081 [-33.081, -33.081] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 21 (20000 steps performed)
999
1 episodes - episode_rewards: -34.510 [-34.510, -34.510] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 22 (21000 steps performed)
999
1 episodes - episode_rewards: -32.531 [-32.531, -32.531] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 23 (22000 steps performed)
999
1 episodes - episode_rewards: -31.768 [-31.768, -31.768] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 24 (23000 steps performed)
999
1 episodes - episode_rewards: -33.629 [-33.629, -33.629] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 25 (24000 steps performed)
999
1 episodes - episode_rewards: -34.097 [-34.097, -34.097] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 26 (25000 steps performed)
999
1 episodes - episode_rewards: -32.551 [-32.551, -32.551] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 27 (26000 steps performed)
999
1 episodes - episode_rewards: -33.061 [-33.061, -33.061] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 28 (27000 steps performed)
999
1 episodes - episode_rewards: -32.640 [-32.640, -32.640] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 29 (28000 steps performed)
999
1 episodes - episode_rewards: -32.304 [-32.304, -32.304] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 30 (29000 steps performed)
999
1 episodes - episode_rewards: -33.940 [-33.940, -33.940] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 31 (30000 steps performed)
999
1 episodes - episode_rewards: -32.541 [-32.541, -32.541] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 32 (31000 steps performed)
999
1 episodes - episode_rewards: -33.913 [-33.913, -33.913] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 33 (32000 steps performed)
999
1 episodes - episode_rewards: -34.716 [-34.716, -34.716] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 34 (33000 steps performed)
999
1 episodes - episode_rewards: -32.384 [-32.384, -32.384] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 35 (34000 steps performed)
999
1 episodes - episode_rewards: -33.301 [-33.301, -33.301] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 36 (35000 steps performed)
999
1 episodes - episode_rewards: -34.000 [-34.000, -34.000] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 37 (36000 steps performed)
999
1 episodes - episode_rewards: -32.529 [-32.529, -32.529] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 38 (37000 steps performed)
999
1 episodes - episode_rewards: -33.617 [-33.617, -33.617] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 39 (38000 steps performed)
999
1 episodes - episode_rewards: -34.800 [-34.800, -34.800] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 40 (39000 steps performed)
999
1 episodes - episode_rewards: -32.964 [-32.964, -32.964] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 41 (40000 steps performed)
999
1 episodes - episode_rewards: -33.512 [-33.512, -33.512] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 42 (41000 steps performed)
999
1 episodes - episode_rewards: -33.488 [-33.488, -33.488] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 43 (42000 steps performed)
999
1 episodes - episode_rewards: -33.581 [-33.581, -33.581] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 44 (43000 steps performed)
999
1 episodes - episode_rewards: -33.969 [-33.969, -33.969] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 45 (44000 steps performed)
999
1 episodes - episode_rewards: -34.272 [-34.272, -34.272] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 46 (45000 steps performed)
999
1 episodes - episode_rewards: -32.500 [-32.500, -32.500] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 47 (46000 steps performed)
999
1 episodes - episode_rewards: -34.001 [-34.001, -34.001] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 48 (47000 steps performed)
999
1 episodes - episode_rewards: -33.512 [-33.512, -33.512] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 49 (48000 steps performed)
999
1 episodes - episode_rewards: -32.651 [-32.651, -32.651] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 50 (49000 steps performed)
999
1 episodes - episode_rewards: -33.843 [-33.843, -33.843] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 51 (50000 steps performed)
999
1 episodes - episode_rewards: -33.716 [-33.716, -33.716] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 52 (51000 steps performed)
999
1 episodes - episode_rewards: -33.637 [-33.637, -33.637] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 53 (52000 steps performed)
999
1 episodes - episode_rewards: -34.786 [-34.786, -34.786] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 54 (53000 steps performed)
999
1 episodes - episode_rewards: -33.554 [-33.554, -33.554] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 55 (54000 steps performed)
999
1 episodes - episode_rewards: -30.896 [-30.896, -30.896] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 56 (55000 steps performed)
999
1 episodes - episode_rewards: -33.901 [-33.901, -33.901] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 57 (56000 steps performed)
999
1 episodes - episode_rewards: -33.758 [-33.758, -33.758] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 58 (57000 steps performed)
999
1 episodes - episode_rewards: -32.098 [-32.098, -32.098] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 59 (58000 steps performed)
999
1 episodes - episode_rewards: -34.206 [-34.206, -34.206] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 60 (59000 steps performed)
999
1 episodes - episode_rewards: -32.869 [-32.869, -32.869] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 61 (60000 steps performed)
999
1 episodes - episode_rewards: -32.077 [-32.077, -32.077] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 62 (61000 steps performed)
999
1 episodes - episode_rewards: -33.362 [-33.362, -33.362] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 63 (62000 steps performed)
999
1 episodes - episode_rewards: -34.554 [-34.554, -34.554] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 64 (63000 steps performed)
999
1 episodes - episode_rewards: -33.251 [-33.251, -33.251] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 65 (64000 steps performed)
999
1 episodes - episode_rewards: -33.037 [-33.037, -33.037] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 66 (65000 steps performed)
999
1 episodes - episode_rewards: -31.459 [-31.459, -31.459] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 67 (66000 steps performed)
999
1 episodes - episode_rewards: -31.674 [-31.674, -31.674] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 68 (67000 steps performed)
999
1 episodes - episode_rewards: -34.268 [-34.268, -34.268] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 69 (68000 steps performed)
999
1 episodes - episode_rewards: -33.685 [-33.685, -33.685] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 70 (69000 steps performed)
999
1 episodes - episode_rewards: -30.762 [-30.762, -30.762] - Model Order: 0.0000 - Training Loss: 0.0009
Interval 71 (70000 steps performed)
999
1 episodes - episode_rewards: -34.488 [-34.488, -34.488] - Model Order: 0.0000 - Training Loss: 0.0011
Interval 72 (71000 steps performed)
999
1 episodes - episode_rewards: -32.638 [-32.638, -32.638] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 73 (72000 steps performed)
999
1 episodes - episode_rewards: -33.810 [-33.810, -33.810] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 74 (73000 steps performed)
999
1 episodes - episode_rewards: -32.639 [-32.639, -32.639] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 75 (74000 steps performed)
999
1 episodes - episode_rewards: -32.581 [-32.581, -32.581] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 76 (75000 steps performed)
999
1 episodes - episode_rewards: -34.152 [-34.152, -34.152] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 77 (76000 steps performed)
999
1 episodes - episode_rewards: -33.267 [-33.267, -33.267] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 78 (77000 steps performed)
999
1 episodes - episode_rewards: -32.221 [-32.221, -32.221] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 79 (78000 steps performed)
999
1 episodes - episode_rewards: -32.979 [-32.979, -32.979] - Model Order: 0.0000 - Training Loss: 0.0010
Interval 80 (79000 steps performed)
