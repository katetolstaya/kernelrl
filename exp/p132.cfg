cfg/exp/p13.cfg
MountainCarContinuous-v0
Training for 500000 steps ...
Interval 1 (0 steps performed)
1 episodes - episode_rewards: -32.945 [-32.945, -32.945] - Model Order: 0.0 - Training Loss: 0.000980602975854
Interval 2 (1000 steps performed)
1 episodes - episode_rewards: -32.946 [-32.946, -32.946] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00100463366256 - Testing Loss: 0.0
Interval 3 (2000 steps performed)
1 episodes - episode_rewards: -33.453 [-33.453, -33.453] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00101205455947 - Testing Loss: 0.0
Interval 4 (3000 steps performed)
1 episodes - episode_rewards: -34.444 [-34.444, -34.444] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00102723214185 - Testing Loss: 0.0
Interval 5 (4000 steps performed)
1 episodes - episode_rewards: -33.115 [-33.115, -33.115] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000987478549089 - Testing Loss: 0.0
Interval 6 (5000 steps performed)
1 episodes - episode_rewards: -34.111 [-34.111, -34.111] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.0010433489916 - Testing Loss: 0.0
Interval 7 (6000 steps performed)
1 episodes - episode_rewards: -30.978 [-30.978, -30.978] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000913501195433 - Testing Loss: 0.0
Interval 8 (7000 steps performed)
1 episodes - episode_rewards: -34.878 [-34.878, -34.878] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00107477151514 - Testing Loss: 0.0
Interval 9 (8000 steps performed)
1 episodes - episode_rewards: -33.383 [-33.383, -33.383] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000997430910808 - Testing Loss: 0.0
Interval 10 (9000 steps performed)
1 episodes - episode_rewards: -32.756 [-32.756, -32.756] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000977274903367 - Testing Loss: 0.0
Interval 11 (10000 steps performed)
1 episodes - episode_rewards: -31.628 [-31.628, -31.628] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000903244477352 - Testing Loss: 0.0
Interval 12 (11000 steps performed)
1 episodes - episode_rewards: -34.298 [-34.298, -34.298] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00103979394029 - Testing Loss: 0.0
Interval 13 (12000 steps performed)
1 episodes - episode_rewards: -32.220 [-32.220, -32.220] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000958323056794 - Testing Loss: 0.0
Interval 14 (13000 steps performed)
1 episodes - episode_rewards: -32.486 [-32.486, -32.486] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000960173586613 - Testing Loss: 0.0
Interval 15 (14000 steps performed)
1 episodes - episode_rewards: -34.491 [-34.491, -34.491] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00104396973954 - Testing Loss: 0.0
Interval 16 (15000 steps performed)
1 episodes - episode_rewards: -33.507 [-33.507, -33.507] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00101430000623 - Testing Loss: 0.0
Interval 17 (16000 steps performed)
1 episodes - episode_rewards: -31.785 [-31.785, -31.785] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000938514133171 - Testing Loss: 0.0
Interval 18 (17000 steps performed)
1 episodes - episode_rewards: -32.525 [-32.525, -32.525] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000975905318542 - Testing Loss: 0.0
Interval 19 (18000 steps performed)
1 episodes - episode_rewards: -31.860 [-31.860, -31.860] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000926595648216 - Testing Loss: 0.0
Interval 20 (19000 steps performed)
1 episodes - episode_rewards: -35.251 [-35.251, -35.251] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00109124909798 - Testing Loss: 0.0
Interval 21 (20000 steps performed)
1 episodes - episode_rewards: -32.382 [-32.382, -32.382] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00097570098154 - Testing Loss: 0.0
Interval 22 (21000 steps performed)
1 episodes - episode_rewards: -31.353 [-31.353, -31.353] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000899403347452 - Testing Loss: 0.0
Interval 23 (22000 steps performed)
1 episodes - episode_rewards: -32.654 [-32.654, -32.654] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000978684200424 - Testing Loss: 0.0
Interval 24 (23000 steps performed)
1 episodes - episode_rewards: -35.704 [-35.704, -35.704] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00109131070344 - Testing Loss: 0.0
Interval 25 (24000 steps performed)
1 episodes - episode_rewards: -33.727 [-33.727, -33.727] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00103101172225 - Testing Loss: 0.0
Interval 26 (25000 steps performed)
1 episodes - episode_rewards: -33.312 [-33.312, -33.312] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000997345676433 - Testing Loss: 0.0
Interval 27 (26000 steps performed)
1 episodes - episode_rewards: -33.929 [-33.929, -33.929] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00104035296473 - Testing Loss: 0.0
Interval 28 (27000 steps performed)
1 episodes - episode_rewards: -33.305 [-33.305, -33.305] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000975948963283 - Testing Loss: 0.0
Interval 29 (28000 steps performed)
1 episodes - episode_rewards: -33.886 [-33.886, -33.886] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00103628865819 - Testing Loss: 0.0
Interval 30 (29000 steps performed)
1 episodes - episode_rewards: -32.782 [-32.782, -32.782] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000996670306135 - Testing Loss: 0.0
Interval 31 (30000 steps performed)
1 episodes - episode_rewards: -32.336 [-32.336, -32.336] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000974680599218 - Testing Loss: 0.0
Interval 32 (31000 steps performed)
1 episodes - episode_rewards: -32.187 [-32.187, -32.187] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000965920774017 - Testing Loss: 0.0
Interval 33 (32000 steps performed)
1 episodes - episode_rewards: -35.395 [-35.395, -35.395] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00108627142452 - Testing Loss: 0.0
Interval 34 (33000 steps performed)
1 episodes - episode_rewards: -34.457 [-34.457, -34.457] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00102804931471 - Testing Loss: 0.0
Interval 35 (34000 steps performed)
1 episodes - episode_rewards: -33.766 [-33.766, -33.766] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00104584691521 - Testing Loss: 0.0
Interval 36 (35000 steps performed)
1 episodes - episode_rewards: -33.875 [-33.875, -33.875] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00102785141125 - Testing Loss: 0.0
Interval 37 (36000 steps performed)
1 episodes - episode_rewards: -32.969 [-32.969, -32.969] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000971479693627 - Testing Loss: 0.0
Interval 38 (37000 steps performed)
1 episodes - episode_rewards: -33.957 [-33.957, -33.957] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00102147445664 - Testing Loss: 0.0
Interval 39 (38000 steps performed)
1 episodes - episode_rewards: -32.665 [-32.665, -32.665] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000983405594329 - Testing Loss: 0.0
Interval 40 (39000 steps performed)
1 episodes - episode_rewards: -32.569 [-32.569, -32.569] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000985142459457 - Testing Loss: 0.0
Interval 41 (40000 steps performed)
1 episodes - episode_rewards: -33.654 [-33.654, -33.654] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00103203748924 - Testing Loss: 0.0
Interval 42 (41000 steps performed)
1 episodes - episode_rewards: -33.957 [-33.957, -33.957] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00102296824336 - Testing Loss: 0.0
Interval 43 (42000 steps performed)
1 episodes - episode_rewards: -33.947 [-33.947, -33.947] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000999835150988 - Testing Loss: 0.0
Interval 44 (43000 steps performed)
1 episodes - episode_rewards: -31.514 [-31.514, -31.514] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000916349426529 - Testing Loss: 0.0
Interval 45 (44000 steps performed)
1 episodes - episode_rewards: -32.756 [-32.756, -32.756] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.000985276368768 - Testing Loss: 0.0
Interval 46 (45000 steps performed)
1 episodes - episode_rewards: -34.311 [-34.311, -34.311] - Model Order: 0.0 - Testing Reward: 0.0000 - Training Loss: 0.00101359533589 - Testing Loss: 0.0
Interval 47 (46000 steps performed)
